{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to [OpenAI Agents SDK](https://openai.github.io/openai-agents-python/)\n",
    "\n",
    "- Allows you to build agentic AI apps in a lightweight, easy-to-use package with very few abstractions. \n",
    "- Small set of primitives:\n",
    "  - Agents: LLMs equipped with instructions and tools\n",
    "  - Handoffs: allow agents to delegate to other agents for specific tasks\n",
    "  - Guardrails: enable validation of agent inputs and outputs\n",
    "  - Sessions: automatically maintains conversation history across agent runs\n",
    "\n",
    "It also includes **built-in tracing**: lets you visualize and debug your agentic flows, as well as evaluate them and even fine-tune models for your application.\n",
    "\n",
    "**2 design principles:**\n",
    "\n",
    "1. Enough features to be worth using, but few enough primitives to make it quick to learn.\n",
    "2. Works great out of the box, but you can customize exactly what happens.\n",
    "\n",
    "## Main features:\n",
    "\n",
    "- Agent loop: Built-in agent loop that handles calling tools, sending results to the LLM, and looping until the LLM is done.\n",
    "- Python-first: Use built-in language features to orchestrate and chain agents, rather than needing to learn new abstractions.\n",
    "- Handoffs: A powerful feature to coordinate and delegate between multiple agents.\n",
    "- Guardrails: Run input validations and checks in parallel to your agents, breaking early if the checks fail.\n",
    "- Sessions: Automatic conversation history management across agent runs, eliminating manual state handling.\n",
    "- Function tools: Turn any Python function into a tool, with automatic schema generation and Pydantic-powered validation.\n",
    "- Tracing: Built-in tracing that lets you visualize, debug and monitor your workflows, as well as use the OpenAI suite of evaluation, fine-tuning and distillation tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Code Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your openai API key\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"var: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function calls itself  \n",
      "Looping inward, depth unwinds  \n",
      "Base case whispers stop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4 (_run):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/greatmaster/miniconda3/envs/openai-agents-sdk/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/greatmaster/miniconda3/envs/openai-agents-sdk/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/Users/greatmaster/miniconda3/envs/openai-agents-sdk/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/greatmaster/miniconda3/envs/openai-agents-sdk/lib/python3.11/site-packages/agents/tracing/processors.py\", line 228, in _run\n",
      "    self._export_batches(force=False)\n",
      "  File \"/Users/greatmaster/miniconda3/envs/openai-agents-sdk/lib/python3.11/site-packages/agents/tracing/processors.py\", line 261, in _export_batches\n",
      "    self._exporter.export(items_to_export)\n",
      "  File \"/Users/greatmaster/miniconda3/envs/openai-agents-sdk/lib/python3.11/site-packages/agents/tracing/processors.py\", line 111, in export\n",
      "    response = self._client.post(url=self.endpoint, headers=headers, json=payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/greatmaster/miniconda3/envs/openai-agents-sdk/lib/python3.11/site-packages/httpx/_client.py\", line 1144, in post\n",
      "    return self.request(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/Users/greatmaster/miniconda3/envs/openai-agents-sdk/lib/python3.11/site-packages/httpx/_client.py\", line 812, in request\n",
      "    request = self.build_request(\n",
      "              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/greatmaster/miniconda3/envs/openai-agents-sdk/lib/python3.11/site-packages/httpx/_client.py\", line 378, in build_request\n",
      "    return Request(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/greatmaster/miniconda3/envs/openai-agents-sdk/lib/python3.11/site-packages/httpx/_models.py\", line 408, in __init__\n",
      "    headers, stream = encode_request(\n",
      "                      ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/greatmaster/miniconda3/envs/openai-agents-sdk/lib/python3.11/site-packages/httpx/_content.py\", line 216, in encode_request\n",
      "    return encode_json(json)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/greatmaster/miniconda3/envs/openai-agents-sdk/lib/python3.11/site-packages/httpx/_content.py\", line 177, in encode_json\n",
      "    body = json_dumps(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/greatmaster/miniconda3/envs/openai-agents-sdk/lib/python3.11/json/__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/Users/greatmaster/miniconda3/envs/openai-agents-sdk/lib/python3.11/json/encoder.py\", line 200, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/greatmaster/miniconda3/envs/openai-agents-sdk/lib/python3.11/json/encoder.py\", line 258, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/greatmaster/miniconda3/envs/openai-agents-sdk/lib/python3.11/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type property is not JSON serializable\n"
     ]
    }
   ],
   "source": [
    "# this import is for running it on a jupyter notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from agents import Agent, Runner\n",
    "\n",
    "\n",
    "# Setup your agent with custom instructions (here we're using the default model)\n",
    "agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\", model='gpt-5-mini')\n",
    "\n",
    "# Run your agent\n",
    "result = Runner.run_sync(agent, \"Write a haiku about recursion in programming.\")\n",
    "\n",
    "# Print the output\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short answer — a practical, widely agreed list (subjective) as of August 27, 2025:\n",
      "\n",
      "1) LangChain — the de facto, ecosystem-first framework for building LLM agents and RAG/chain workflows; massive community, mature docs and tooling (Python + JS). ([github.com](https://github.com/langchain-ai/langchain?utm_source=chatgpt.com), [repositorystats.com](https://repositorystats.com/langchain-ai/langchain?utm_source=chatgpt.com))\n",
      "\n",
      "2) Microsoft AutoGen — Microsoft’s multi‑agent programming framework (with AutoGen Studio/benching, extensions, and enterprise integrations) aimed at complex conversational/multi‑agent workflows. ([github.com](https://github.com/microsoft/autogen?utm_source=chatgpt.com), [microsoft.com](https://www.microsoft.com/en-us/research/project/autogen/overview/?utm_source=chatgpt.com))\n",
      "\n",
      "3) MetaGPT (and MetaGPT X / MGX) — role‑based multi‑agent framework that encodes SOPs (Product Manager / Engineer roles, etc.) and has become a go‑to for multi‑agent software workflows. ([gh.loli.garden](https://gh.loli.garden/geekan/MetaGPT?utm_source=chatgpt.com), [arxiv.org](https://arxiv.org/abs/2308.00352?utm_source=chatgpt.com))\n",
      "\n",
      "4) Dify — an open‑source LLM app / agent platform (visual workflow + RAG + built‑in tools and observability) that’s grown fast as a production‑oriented agent/workflow stack. ([dify.ai](https://dify.ai/?utm_source=chatgpt.com), [github.com](https://github.com/langgenius/dify?utm_source=chatgpt.com))\n",
      "\n",
      "5) Amazon Bedrock AgentCore (AWS AgentCore) — AWS’s enterprise agent platform (AgentCore on Bedrock) for building, running and governing production agent fleets — a major enterprise entrant in 2025. ([techradar.com](https://www.techradar.com/pro/aws-looks-to-super-charge-ai-agents-with-amazon-bedrock-agentcore?utm_source=chatgpt.com))\n",
      "\n",
      "Notes and context\n",
      "- “Top” is inherently subjective. I ranked these by a combination of developer/community traction (GitHub/ecosystem), breadth of features (multi‑agent support, tools, RAG, observability), and enterprise momentum (cloud vendor offerings and press). If you want a different ranking (e.g., by GitHub stars, ease‑of‑use, or enterprise readiness), I can re-sort and show the metrics.\n",
      "- Honorable mentions: LangGraph / LangChain’s LangGraph (graph‑style stateful workflows), LangFlow / Flowise (visual builders), SuperAGI, Microsoft Semantic Kernel, OpenAI Swarm / Agents SDK, and several newer open‑source projects (Atomic Agents, Agno, etc.). These are worth considering depending on your use case. ([github.com](https://github.com/langchain-ai?utm_source=chatgpt.com), [yuxiaopeng.com](https://yuxiaopeng.com/Github-Ranking-AI/?utm_source=chatgpt.com))\n",
      "\n",
      "Would you like:\n",
      "- a comparison table (features, language, maturity, license, typical use cases), or\n",
      "- a recommendation for a specific use case (production customer service bot, research assistant, autonomous automation, on‑prem/self‑hosted, etc.)?\n"
     ]
    }
   ],
   "source": [
    "from agents.tool import WebSearchTool\n",
    "\n",
    "agent = Agent(name=\"Web Search Agent\", \n",
    "              instructions='You research online with the WebSearchTool and you answer the question from the user.',\n",
    "              model='gpt-5-mini',\n",
    "              tools=[WebSearchTool()])\n",
    "\n",
    "result = Runner.run_sync(agent, 'What are the top 5 agent frameworks in 2025?')\n",
    "\n",
    "print(result.final_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-agents-sdk",
   "language": "python",
   "name": "openai-agents-sdk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
