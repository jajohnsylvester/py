{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53e47c17",
   "metadata": {},
   "source": [
    "# Intro Agents from Scratch\n",
    "\n",
    "## 3 Levels\n",
    "\n",
    "1. LLMs + functions in prompt\n",
    "2. LLMs + structured outputs/function calling\n",
    "3. Agent loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d73b156",
   "metadata": {},
   "source": [
    "### 1. LLMs + functions in prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffa79bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Could you share what domain you mean by “agents”? For example:\\n- AI/LLM or robotics agents (autonomy levels)\\n- Customer support agents (Tier 1/2/3)\\n- Real estate agents (salesperson, broker, managing broker)\\n- Game/CS agents (reactive vs deliberative)\\n- Level‑k reasoning in multi‑agent games (L0, L1, L2…)\\n\\nIf you mean AI/LLM agents, a common ladder of “agent levels” is:\\n1) Tool-augmented assistant: answers plus single tool calls (search, code exec).\\n2) Multi-step planner: decomposes tasks and uses multiple tools/steps.\\n3) Reflective agent: iterates, critiques itself, uses memory/context to improve.\\n4) Goal-driven autonomous worker: runs long tasks, monitors progress/events, minimal supervision.\\n5) Orchestrated multi-agent system: multiple specialized agents coordinated by a controller.\\n\\nTell me which context you had in mind, and I’ll tailor the levels accordingly.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def get_response(prompt_question):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt_question}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "get_response(\"Hi! What are the levels of agents?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d35ca84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'write_file(\"test.txt\", \"Hello, world!\")'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def write_file(file_path, content):\n",
    "    \"\"\"Takes in a file path and content, and writes the content to the file\"\"\"\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "def read_file(file_path):\n",
    "    \"\"\"Takes in a file path and returns the content of the file\"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def level1_agent_llm_and_functions_in_prompt(prompt):\n",
    "    function_info = \"\"\"\n",
    "    def write_file(file_path, content):\n",
    "        '''Takes in a file path and content, and writes the content to the file'''\n",
    "        with open(file_path, \"w\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "    def read_file(file_path):\n",
    "        '''Takes in a file path and returns the content of the file'''\n",
    "        with open(file_path, \"r\") as f:\n",
    "            return f.read()\n",
    "\n",
    "    \"\"\"\n",
    "    full_prompt_with_function_info = f\"\"\"\n",
    "    Take this request from a user: {prompt}.\n",
    "    If the request involves writing to a file or reading to a file,\n",
    "    you can output a call to these functions which you have access to: \n",
    "    {function_info}.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant that can write and read files.\"},\n",
    "                  {\"role\": \"user\", \"content\": full_prompt_with_function_info}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "    \n",
    "level1_agent_llm_and_functions_in_prompt(\"Write a file called 'test.txt' with the content 'Hello, world!'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a3e8429",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec('write_file(\"test.txt\", \"Hello, world!\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b9ab54",
   "metadata": {},
   "source": [
    "## Level 2: LLMs + structured outputs/function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f02c8a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class WriteFileOperation(BaseModel):\n",
    "    file_path: str = Field(description=\"The path to the file to be written to or read from\")\n",
    "    content: str = Field(description=\"The content to be written to the file\")\n",
    "\n",
    "class ReadFileOperation(BaseModel):\n",
    "    file_path: str = Field(description=\"The path to the file to be written to or read from\")\n",
    "\n",
    "\n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-5\",\n",
    "    messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant that can write and read files.\"},\n",
    "              {\"role\": \"user\", \"content\": \"Write a file called 'test.txt' with the content 'Hello, world!'\"}],\n",
    "    response_format=WriteFileOperation)\n",
    "\n",
    "output_write_file_ops = response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf46fa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.txt\n",
      "Hello, world!\n"
     ]
    }
   ],
   "source": [
    "print(output_write_file_ops.file_path)\n",
    "print(output_write_file_ops.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54cb1b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File was created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WriteFileOperation(file_path='level2agentoutput.txt', content='Level 2 works!')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def level2_agent_llm_structured(prompt):\n",
    "    response = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-5\",\n",
    "    messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant that can write and read files.\"},\n",
    "              {\"role\": \"user\", \"content\": prompt}],\n",
    "    response_format=WriteFileOperation)# Structured OUTPUT from the LLM!\n",
    "    output_args = response.choices[0].message.parsed\n",
    "    # FUNCTION CALLING!\n",
    "    write_file(output_args.file_path, output_args.content)\n",
    "    print(\"File was created!\")\n",
    "    return output_args\n",
    "\n",
    "level2_agent_llm_structured(\"Write a file called 'level2agentoutput.txt' with the content 'Level 2 works!'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07f3f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this as sample_input.txt\n",
    "response = get_response(\"Create a 3 paragraph exaplanation of modern llm agents\")\n",
    "write_file(\"sample_input.txt\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d912086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Task: Read the file: 'sample_input.txt' and write a summary of that file into a new file called 'summary_file.txt'\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Agent: THOUGHT: I need to read the content of 'sample_input.txt' to understand its contents before I can write a summary.\n",
      "ACTION: read_file('sample_input.txt')\n",
      "Executing: read_file('sample_input.txt')\n",
      "Observation: Modern LLM agents are software systems that wrap a large language model in an autonomous loop that can plan, act through tools, and adapt based on feedback to pursue a goal. Unlike static chatbots tha...\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Agent: THOUGHT: I have read the content of 'sample_input.txt'. Now, I need to write a concise summary of this content and save it to 'summary_file.txt'.\n",
      "\n",
      "Summary: The text describes modern LLM agents, which are advanced software systems that utilize large language models to autonomously plan, act, and adapt to achieve goals. Unlike static chatbots, these agents execute complex workflows by interfacing with tools, maintaining state, and iterating based on feedback. They consist of components like planners, tool routers, and memory systems, and can operate as single agents or coordinated teams. To ensure reliability, agents use guardrails such as schema validation, human approvals, and monitoring. Despite their power, they require careful task scoping and safe design practices. Future advancements are expected to enhance their capabilities.\n",
      "\n",
      "ACTION: write_file('summary_file.txt', \"The text describes modern LLM agents, which are advanced software systems that utilize large language models to autonomously plan, act, and adapt to achieve goals. Unlike static chatbots, these agents execute complex workflows by interfacing with tools, maintaining state, and iterating based on feedback. They consist of components like planners, tool routers, and memory systems, and can operate as single agents or coordinated teams. To ensure reliability, agents use guardrails such as schema validation, human approvals, and monitoring. Despite their power, they require careful task scoping and safe design practices. Future advancements are expected to enhance their capabilities.\")\n",
      "Executing: write_file('summary_file.txt', \"The text describes modern LLM agents, which are advanced software systems that utilize large language models to autonomously plan, act, and adapt to achieve goals. Unlike static chatbots, these agents execute complex workflows by interfacing with tools, maintaining state, and iterating based on feedback. They consist of components like planners, tool routers, and memory systems, and can operate as single agents or coordinated teams. To ensure reliability, agents use guardrails such as schema validation, human approvals, and monitoring. Despite their power, they require careful task scoping and safe design practices. Future advancements are expected to enhance their capabilities.\")\n",
      "Observation: Successfully wrote to summary_file.txt\n",
      "\n",
      "--- Iteration 3 ---\n",
      "Agent: THOUGHT: I have successfully written the summary of 'sample_input.txt' into 'summary_file.txt'.\n",
      "ANSWER: I have read the content of 'sample_input.txt' and written a summary into 'summary_file.txt'. If you need anything else, feel free to ask!\n",
      "\n",
      "✓ Final Answer: I have read the content of 'sample_input.txt' and written a summary into 'summary_file.txt'. If you need anything else, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "def level3_agent_loop(task_prompt):\n",
    "    \"\"\"\n",
    "    ReAct-style agent loop that iteratively:\n",
    "    1. Observes the current state\n",
    "    2. Thinks about what to do next\n",
    "    3. Takes an action (either calls a tool or provides final answer)\n",
    "    4. Gets observation from the action\n",
    "    5. Repeats until task is complete\n",
    "    \"\"\"\n",
    "    # Available tools that the agent can use\n",
    "    available_tools = {\n",
    "        'read_file': read_file,\n",
    "        'write_file': write_file\n",
    "    }\n",
    "    \n",
    "    # Initialize conversation history with system prompt\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"You are a helpful assistant that can read and write files.\n",
    "        \n",
    "            You work in a loop where you:\n",
    "            1. Think about what needs to be done\n",
    "            2. Either call a tool OR provide a final answer\n",
    "            3. Observe the result and continue if needed\n",
    "\n",
    "            Available tools:\n",
    "            - read_file(file_path): Reads content from a file\n",
    "            - write_file(file_path, content): Writes content to a file\n",
    "\n",
    "            When you need to use a tool, respond with:\n",
    "            THOUGHT: [your reasoning]\n",
    "            ACTION: [tool_name](arguments)\n",
    "\n",
    "            When you have the final answer, respond with:\n",
    "            THOUGHT: [your reasoning]\n",
    "            ANSWER: [your final response to the user]\n",
    "\n",
    "            Important: Only use ACTION or ANSWER, not both in the same response.\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": task_prompt}\n",
    "    ]\n",
    "    \n",
    "    max_iterations = 10  # Prevent infinite loops\n",
    "    iteration = 0\n",
    "    \n",
    "    print(f\"User Task: {task_prompt}\\n\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    while iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        print(f\"\\n--- Iteration {iteration} ---\")\n",
    "        \n",
    "        # Get LLM response\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",  # Using a model that exists\n",
    "            messages=messages,\n",
    "            temperature=0.1  # Lower temperature for more consistent behavior\n",
    "        )\n",
    "        \n",
    "        agent_response = response.choices[0].message.content\n",
    "        print(f\"Agent: {agent_response}\")\n",
    "        \n",
    "        # Add agent's response to conversation history\n",
    "        messages.append({\"role\": \"assistant\", \"content\": agent_response})\n",
    "        \n",
    "        # Parse the response to determine if it's an action or final answer\n",
    "        if \"ANSWER:\" in agent_response:\n",
    "            # Agent has provided final answer\n",
    "            answer = agent_response.split(\"ANSWER:\")[1].strip()\n",
    "            print(f\"\\n✓ Final Answer: {answer}\")\n",
    "            return answer\n",
    "        \n",
    "        elif \"ACTION:\" in agent_response:\n",
    "            # Agent wants to execute a tool\n",
    "            action_line = agent_response.split(\"ACTION:\")[1].strip().split('\\n')[0].strip()\n",
    "            \n",
    "            try:\n",
    "                # Parse the function call\n",
    "                import re\n",
    "                match = re.match(r'(\\w+)\\((.*)\\)', action_line)\n",
    "                if match:\n",
    "                    tool_name = match.group(1)\n",
    "                    args_str = match.group(2)\n",
    "                    \n",
    "                    if tool_name in available_tools:\n",
    "                        # Execute the tool\n",
    "                        print(f\"Executing: {action_line}\")\n",
    "                        \n",
    "                        # Parse arguments (simple parsing for demo)\n",
    "                        if tool_name == 'read_file':\n",
    "                            # Extract file path from quotes\n",
    "                            file_path = args_str.strip('\\'\"')\n",
    "                            observation = available_tools[tool_name](file_path)\n",
    "                        elif tool_name == 'write_file':\n",
    "                            # Split by comma and extract both arguments\n",
    "                            parts = args_str.split(',', 1)\n",
    "                            file_path = parts[0].strip().strip('\\'\"')\n",
    "                            content = parts[1].strip().strip('\\'\"') if len(parts) > 1 else \"\"\n",
    "                            available_tools[tool_name](file_path, content)\n",
    "                            observation = f\"Successfully wrote to {file_path}\"\n",
    "                        \n",
    "                        print(f\"Observation: {observation[:200]}...\" if len(str(observation)) > 200 else f\"Observation: {observation}\")\n",
    "                        \n",
    "                        # Add observation to conversation\n",
    "                        messages.append({\"role\": \"user\", \"content\": f\"Observation from {tool_name}: {observation}\"})\n",
    "                    else:\n",
    "                        messages.append({\"role\": \"user\", \"content\": f\"Error: Unknown tool '{tool_name}'\"})\n",
    "                else:\n",
    "                    messages.append({\"role\": \"user\", \"content\": f\"Error: Could not parse action '{action_line}'\"})\n",
    "                    \n",
    "            except Exception as e:\n",
    "                error_msg = f\"Error executing action: {str(e)}\"\n",
    "                print(f\"Error: {error_msg}\")\n",
    "                messages.append({\"role\": \"user\", \"content\": error_msg})\n",
    "        else:\n",
    "            # Agent provided neither ACTION nor ANSWER - prompt for clarification\n",
    "            messages.append({\"role\": \"user\", \"content\": \"Please respond with either 'ACTION: tool_name(args)' to use a tool or 'ANSWER: your_response' to provide the final answer.\"})\n",
    "    \n",
    "    print(\"\\n⚠ Maximum iterations reached\")\n",
    "    return \"Maximum iterations reached without completing the task\"\n",
    "    \n",
    "# Test the agent loop\n",
    "prompt = \"Read the file: 'sample_input.txt' and write a summary of that file into a new file called 'summary_file.txt'\"\n",
    "result = level3_agent_loop(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cf1641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
